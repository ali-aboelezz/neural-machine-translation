{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_WSglchgG5x",
        "outputId": "afd79fa5-bc75-412f-9327-c754015779cb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.7 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " import all the required modules"
      ],
      "metadata": {
        "id": "yqNYJ6ZkgIzw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hSf1FY2Oel_Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as f\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field,BucketIterator\n",
        "import spacy\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the random seeds for reproducability"
      ],
      "metadata": {
        "id": "qO9ImMoGeoZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "EHBsqZHShKSv"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "download the german model"
      ],
      "metadata": {
        "id": "mNEYNyR9hlH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy.cli \n",
        "spacy.cli.download(\"de_core_news_sm\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKn4vIymiiKz",
        "outputId": "eb6fd9a2-f9d8-404a-ac61-764dc4a992cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the German and English spaCy models"
      ],
      "metadata": {
        "id": "1VYlksJQpVKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_de = spacy.load('de_core_news_sm')\n",
        "spacy_en = spacy.load('en_core_web_sm')\n"
      ],
      "metadata": {
        "id": "Z-Q1YrEOhlfE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create the tokenizers"
      ],
      "metadata": {
        "id": "o7cwmsdqjRxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_de(text):\n",
        "  return [t.text for t in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "  return [t.text for t in spacy_en.tokenizer(text)]"
      ],
      "metadata": {
        "id": "eL5wURgfjSWv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create the source and target fields"
      ],
      "metadata": {
        "id": "Etf7QUzlj6V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRC = Field(tokenize = tokenize_de,init_token = '<sos>',eos_token='<eos>',lower = True)\n",
        "TRG = Field(tokenize = tokenize_en,init_token = '<sos>',eos_token='<eos>',lower = True)\n",
        "\n"
      ],
      "metadata": {
        "id": "PVCRPiBvj7Mc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data"
      ],
      "metadata": {
        "id": "2-EIL_jamPuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,valid_data,test_data=Multi30k.splits(exts=('.de','.en'),fields=(SRC,TRG))"
      ],
      "metadata": {
        "id": "xaCHe06hmP8F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3649018-8de8-472d-cf9b-6a014beae7c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading training.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 866kB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading validation.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 235kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 219kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the vocabulary and Define the device"
      ],
      "metadata": {
        "id": "7wYIFf10m8Zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRC.build_vocab(train_data,min_freq=2)\n",
        "TRG.build_vocab(train_data,min_freq=2)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "zbUtOmt4m8w9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the iterators"
      ],
      "metadata": {
        "id": "cHOWQkj8ne7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "metadata": {
        "id": "8mXPKRGHnfML"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create the encoder class"
      ],
      "metadata": {
        "id": "H0qLNcpLoKoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from thinc.layers.bidirectional import bidirectional\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self,input_dim,emb_dim,enc_hid_dim,dec_hid_dim,dropout):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding= nn.Embedding(input_dim,emb_dim)\n",
        "\n",
        "    self.rnn = nn.GRU(emb_dim,enc_hid_dim,bidirectional = True )\n",
        "\n",
        "    self.fc = nn.Linear(enc_hid_dim*2,dec_hid_dim)\n",
        "    \n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "  def forward(self,src):\n",
        "\n",
        "    embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "    outputs,hidden = self.rnn(embedded)\n",
        "\n",
        "    hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:],hidden[-1,:,:]),dim=1)))  \n",
        "\n",
        "    return outputs,hidden"
      ],
      "metadata": {
        "id": "7N5EI_-toK_M"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create the attention class"
      ],
      "metadata": {
        "id": "x9e7gQL2rOXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self,enc_hid_dim,dec_hid_dim):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.attn = nn.Linear((enc_hid_dim*2)+dec_hid_dim , dec_hid_dim)\n",
        "    self.v = nn.Linear(dec_hid_dim,1,bias = False)\n",
        "\n",
        "  def forward(self,hidden,encoder_outputs):\n",
        "\n",
        "    batch_size = encoder_outputs.shape[1]\n",
        "    src_len = encoder_outputs.shape[0]\n",
        "    hidden = hidden.unsqueeze(1).repeat(1,src_len,1)\n",
        "    encoder_outputs = encoder_outputs.permute(1,0,2)\n",
        "    energy = torch.tanh(self.attn(torch.cat((hidden,encoder_outputs),dim=2)))\n",
        "    attention = self.v(energy).squeeze(2)\n",
        "\n",
        "    return f.softmax(attention,dim=1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IO-vzcidrOvG"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create the decoder class"
      ],
      "metadata": {
        "id": "iusUikxEztsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,output_dim,emb_dim,enc_hid_dim,dec_hid_dim,dropout,attention):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    \n",
        "    self.output_dim = output_dim\n",
        "    self.attention = attention\n",
        "    self.embedding = nn.Embedding(output_dim,emb_dim)\n",
        "    self.rnn = nn.GRU((enc_hid_dim*2)+emb_dim,dec_hid_dim)\n",
        "    self.fc_out = nn.Linear((enc_hid_dim*2)+dec_hid_dim+emb_dim,output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "  def forward(self,input,hidden,encoder_outputs):\n",
        "\n",
        "    input = input.unsqueeze(0)\n",
        "    embedded = self.dropout(self.embedding(input))\n",
        "    a = self.attention(hidden,encoder_outputs)\n",
        "    a = a.unsqueeze(1)\n",
        "    encoder_outputs = encoder_outputs.permute(1,0,2)\n",
        "    weighted = torch.bmm(a,encoder_outputs)\n",
        "    weighted = weighted.permute(1,0,2)\n",
        "    rnn_input = torch.cat((embedded,weighted),dim=2)\n",
        "    output,hidden = self.rnn(rnn_input,hidden.unsqueeze(0))\n",
        "\n",
        "    assert (output == hidden).all()\n",
        "    embedded = embedded.squeeze(0)\n",
        "    weighted = weighted.squeeze(0)\n",
        "    output = output.squeeze(0)\n",
        "    prediction = self.fc_out(torch.cat((output,weighted,embedded),dim=1))\n",
        "\n",
        "    return prediction,hidden.squeeze(0)\n"
      ],
      "metadata": {
        "id": "heUbNKFTzuEG"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the Seq2Seq Model"
      ],
      "metadata": {
        "id": "m6sTOqKq6ZlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self,encoder,decoder,device):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.device = device\n",
        "\n",
        "\n",
        "  def forward(self,src,trg,teacher_forcing_ratio= 0.5):\n",
        "\n",
        "    \n",
        "    batch_size = src.shape[1]\n",
        "    trg_len =   trg.shape[0]\n",
        "    trg_vocab_size = self.decoder.output_dim\n",
        "    outputs = torch.zeros(trg_len,batch_size,trg_vocab_size).to(self.device)\n",
        "    encoder_outputs,hidden = self.encoder(src)\n",
        "    input = trg[0,:]\n",
        "\n",
        "\n",
        "    for t in range(1,trg_len):\n",
        "      output,hidden = self.decoder(input,hidden,encoder_outputs)\n",
        "      outputs[t]=output\n",
        "      teacher_force = random.random() < teacher_forcing_ratio\n",
        "      top1 = output.argmax(1)\n",
        "      input = trg[t] if teacher_force else top1\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "N0rdyc3H6Z-z"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "initialize the parameters, encoder, decoder and seq2seq model"
      ],
      "metadata": {
        "id": "YXv0GemtztHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Input_dim = len(SRC.vocab)\n",
        "Output_dim = len(TRG.vocab)\n",
        "Enc_emb_dim = 256\n",
        "Dec_emb_dim = 256\n",
        "Enc_hid_dim = 512\n",
        "Dec_hid_dim = 512\n",
        "Enc_dropout = 0.5\n",
        "Dec_dropout = 0.5\n",
        "\n",
        "attn = Attention(Enc_hid_dim,Dec_hid_dim)\n",
        "enc = Encoder(Input_dim,Enc_emb_dim,Enc_hid_dim,Dec_hid_dim,Enc_dropout)\n",
        "dec = Decoder(Output_dim,Dec_emb_dim,Enc_hid_dim,Dec_hid_dim,Dec_dropout,attn)\n",
        "\n",
        "model = Seq2Seq(enc,dec,device).to(device)"
      ],
      "metadata": {
        "id": "LX7U0Cao4g2b"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will initialize all biases to zero and all weights from  N(0,0.01)\n"
      ],
      "metadata": {
        "id": "mpWU7W1m4hLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "  for name , param in m.named_parameters():\n",
        "    if 'weight' in name:\n",
        "      nn.init.normal_(param.data,mean=0,std=0.01)\n",
        "    else :\n",
        "      nn.init.constant_(param.data,0)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asS0svQg4hlQ",
        "outputId": "ca1d447f-aa94-43dd-96c3-d100a8d3d3af"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(7853, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(5893, 256)\n",
              "    (rnn): GRU(1280, 512)\n",
              "    (fc_out): Linear(in_features=1792, out_features=5893, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create an optimizer"
      ],
      "metadata": {
        "id": "bx313e-nBJUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n"
      ],
      "metadata": {
        "id": "ZEr3CskTBJqF"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "initialize the loss function"
      ],
      "metadata": {
        "id": "71p7TyOnqn81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "metadata": {
        "id": "O9Msk-OTdbns"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create the training function"
      ],
      "metadata": {
        "id": "1knQde_iB0pT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,iterator,optimizer,criterion,clip):\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  for i,batch in enumerate(iterator):\n",
        "    src = batch.src\n",
        "    trg = batch.trg\n",
        "    optimizer.zero_grad()\n",
        "    output = model(src,trg)\n",
        "    output_dim = output.shape[-1]\n",
        "    output = output[1:].view(-1,output_dim)\n",
        "    trg = trg[1:].view(-1)\n",
        "    loss = criterion(output,trg)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(),clip)\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "  return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "8Y3ZTf_mB02E"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create the evaluation function"
      ],
      "metadata": {
        "id": "OrjHU6-rDdo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model,iterator,criterion):\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  for i ,batch in enumerate(iterator):\n",
        "    src = batch.src\n",
        "    trg = batch.trg\n",
        "    output = model(src,trg)\n",
        "    output_dim = output.shape[-1]\n",
        "    output = output[1:].view(-1,output_dim)\n",
        "    trg = trg[1:].view(-1)\n",
        "    loss = criterion(output,trg)\n",
        "    epoch_loss += loss.item()\n",
        "  return epoch_loss/len(iterator)  "
      ],
      "metadata": {
        "id": "UXZsuolYDeAb"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define a timing function"
      ],
      "metadata": {
        "id": "9BFGAwuDEcNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time,end_time):\n",
        "  el_time = end_time - start_time\n",
        "  el_mins = int(el_time/60)\n",
        "  el_secs = int(el_time - el_mins *60)\n",
        "  return el_mins , el_secs"
      ],
      "metadata": {
        "id": "5PRnrh9dEcc8"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we train our model and saving the parameters that give us the best validation loss"
      ],
      "metadata": {
        "id": "O5zKbRveFMKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zns1CVQyFMad",
        "outputId": "bc47a05a-048c-4914-e0de-31700d9466f5"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 1m 19s\n",
            "\tTrain Loss: 5.067 | Train PPL: 158.673\n",
            "\t Val. Loss: 4.461 |  Val. PPL:  86.605\n",
            "Epoch: 02 | Time: 1m 21s\n",
            "\tTrain Loss: 4.197 | Train PPL:  66.471\n",
            "\t Val. Loss: 3.816 |  Val. PPL:  45.412\n",
            "Epoch: 03 | Time: 1m 22s\n",
            "\tTrain Loss: 3.474 | Train PPL:  32.258\n",
            "\t Val. Loss: 2.957 |  Val. PPL:  19.234\n",
            "Epoch: 04 | Time: 1m 22s\n",
            "\tTrain Loss: 2.923 | Train PPL:  18.605\n",
            "\t Val. Loss: 2.758 |  Val. PPL:  15.773\n",
            "Epoch: 05 | Time: 1m 22s\n",
            "\tTrain Loss: 2.537 | Train PPL:  12.642\n",
            "\t Val. Loss: 2.504 |  Val. PPL:  12.227\n",
            "Epoch: 06 | Time: 1m 22s\n",
            "\tTrain Loss: 2.226 | Train PPL:   9.263\n",
            "\t Val. Loss: 2.408 |  Val. PPL:  11.112\n",
            "Epoch: 07 | Time: 1m 23s\n",
            "\tTrain Loss: 2.002 | Train PPL:   7.402\n",
            "\t Val. Loss: 2.448 |  Val. PPL:  11.567\n",
            "Epoch: 08 | Time: 1m 22s\n",
            "\tTrain Loss: 1.778 | Train PPL:   5.919\n",
            "\t Val. Loss: 2.463 |  Val. PPL:  11.738\n",
            "Epoch: 09 | Time: 1m 22s\n",
            "\tTrain Loss: 1.633 | Train PPL:   5.120\n",
            "\t Val. Loss: 2.374 |  Val. PPL:  10.745\n",
            "Epoch: 10 | Time: 1m 23s\n",
            "\tTrain Loss: 1.503 | Train PPL:   4.493\n",
            "\t Val. Loss: 2.442 |  Val. PPL:  11.493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we test the model on the test set using these best parameters"
      ],
      "metadata": {
        "id": "ItAug3NTnICg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('tut3-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI6FPYVxnJTl",
        "outputId": "fb9ae38b-6767-4f78-f705-34a83f00aaa3"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 2.375 | Test PPL:  10.752 |\n"
          ]
        }
      ]
    }
  ]
}